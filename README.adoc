= cache-demo-source =

Demo (simple) accompagnant la https://github.com/ptitbob/cache-demo[presentation de la gestion du cache avec Spring].

== _Introduction_ ==

NOTE: Cette doc n'explique pas les différences entre chaque système de cache, ni leur mise en application. Pour cela, la presentation et les articles (urls à venir) vous apporteront les réponses.

L'application presente quelques URLs afin de valider la notion de cache.
Elle organise ses donnée depuis 2 tables décrite dans le container `app-db`.
Un accès HTTP simulant un accès long `ping-app`.
Et un autre accès HTTP revoyant des données relativement importante `zipcode-app` ayant sa propre base de donnée (`zipcode-db`).

image:documentation/application.png[]

Les sources des application tierce sont dans les repertoires :

* pingapp
* zipcode

Les sources des containers se trouvent dans le repertoire docker.
Les sources des container de l'applicatifs sont propre à chaque branche (et donc chaque test de solution de cache).
Si pour un test, il est requis un serveur (redis & ehcache distribué), celui-ci est décrit dans le fichier docker-compose.
Les autres container (pingapp, zipcode [app & DB], base de donnée de l'applicatif).

Chaque utilisation est isolée dans une branche
(auquelle vous pouvez acceder via le lien en chaque début de section de cette documentation, en selectionnant la branche via l'IHM github ou en réalisant un checkout en local sur votre poste).

* ehCache in-memory
* ehCache distribué - serveur terracotta OSS
* REDIS distribué - serveur REDIS
* Hazelcast

Le load balancing sur les deux noeud de l'application est assuré par un NGINX qui permet aussi d'acceder à pgAdmin.

Afin de permettre l'accès via nGinx, vous devez configurer votre fichier `Hosts` :

```
# pour la demo spring cache
127.0.0.1   docker.local
fe80::1%lo0 pgadmin.docker.local
127.0.0.1   pgadmin.docker.local
fe80::1%lo0 glowroot.docker.local
127.0.0.1   glowroot.docker.local
fe80::1%lo0 zipcode.docker.local
127.0.0.1   zipcode.docker.local
fe80::1%lo0 ping.docker.local
127.0.0.1   ping.docker.local
fe80::1%lo0 app.docker.local
127.0.0.1   app.docker.local
```

Pour lancer l'envirronement de test, il suffit (dans la branche de votre choix) d'executer la commande suivante :

```
docker-compose up -d
```

TIP: Pour rappel, pour suivre les logs d'un container en particulier, executez la commande suivante : `docker logs -f [Nom du container]`



== les URLs ==

L'application expose une serie d'URLs qui sont disponible sous forme de documentation swagger 2.0, ainsi que l'IHM swagger-ui :

* local (execution) - swagger : http://localhost:8080/api/v2/api-docs
** local (execution) - swagger UI : http://localhost:8080/api/swagger-ui.html
* Container - swagger : http://app.docker.local/api/v2/api-docs
** Container - swagger UI : http://app.docker.local/api/swagger-ui.html

Les applications associées exposent de même :

* http://ping.docker.local/api/v2/api-docs
** http://ping.docker.local/api/swagger-ui.html
* http://zipcode.docker.local/api/v2/api-docs
** http://zipcode.docker.local/api/swagger-ui.htmldocs

== pgAdmin ==

pgAdmin vous permet de vous connecter au différentes base postgres utilisé.

Pour vous connecter :

* url : http://pgadmin.docker.local/
* login (mail) : pgadmin4@pgadmin.org
* password : admin

Pour acceder aux DB, vous devrez au préalable les enregistrer.

* DB de l'application de test
** host : app-db
** user : postgres
** password : postgres
* DB de l'application ville (insee & code postal)
** host : zipcode-db
** user : postgres
** password : postgres

== ehCache in-memory ==

La gestion de cache in-memory sur un cluster, implique au minimun de pouvoir invalider le cache de manière asynchrone.
Cet exemple arrivera en dernier, car cela neccessite un processus particulier.

== ehCache distribué ==

Branche: https://github.com/ptitbob/cache-demo-source/tree/ehcache-distribue

== Redis distribué ==

Branche: https://github.com/ptitbob/cache-demo-source/tree/redis-distribue

Afin de verifier les accès au cache, `redis` offre un cli bien pratique.

Pour y acceder :

```
docker exec -it redis bash
```
Puis
```
redis-cli
```
Et maintenant le monitoring :
```
monitor
```

Lors d'un primo accès, vous devriez obtenir ceci:
```
1545659237.142891 [0 172.19.0.1:33824] "SET" "message::TOT" "\xac\xed\x00\x05sr\x00+org.shipstone.demo.cache.app.domain.MessageIT\xfb\xa1\xc7LF6\x02\x00\x03L\x00\x04codet\x00\x12Ljava/lang/String;L\x00\x02idt\x00\x10Ljava/lang/Long;L\x00\amessageq\x00~\x00\x01xpt\x00\x03TOTsr\x00\x0ejava.lang.Long;\x8b\xe4\x90\xcc\x8f#\xdf\x02\x00\x01J\x00\x05valuexr\x00\x10java.lang.Number\x86\xac\x95\x1d\x0b\x94\xe0\x8b\x02\x00\x00xp\x00\x00\x00\x00\x00\x00\x00[t\x00\x130+0=la t\xc3\xaate a toto" "PX" "6000"
1545659238.737308 [0 172.19.0.1:33824] "GET" "message::TOT"
```

et pour un accès sur une donnée déjà en cache:
```
1545659240.008038 [0 172.19.0.1:33824] "GET" "message::TOT"
```

https://redis.io/topics/rediscli[Liste des commandes redis-cli]

== Hazelcast ==

Branche : https://github.com/ptitbob/cache-demo-source/tree/hazelcast

Dépendance a ajouter :

[source,xml]
----
<dependency>
    <groupId>com.hazelcast</groupId>
    <artifactId>hazelcast</artifactId>
</dependency>
<dependency>
    <groupId>com.hazelcast</groupId>
    <artifactId>hazelcast-spring</artifactId>
</dependency>
----

Mais pour une raison que je m'explique pas encore, hazelcast semble ne pas aimer cette dépendance (donc a supprimer) :
[source,xml]
----
<dependency>
    <groupId>javax.cache</groupId>
    <artifactId>cache-api</artifactId>
</dependency>
----

Configuration de l'application :

[source,yaml]
----
spring:
  hazelcast:
    config: classpath:hazelcast.xml
----

Et ajout du fichier de configuration `hazelcast.xml`.

L'application packagée pour la containerisation (`app-1.0-HAZELCAST.jar`) est disponible avec l'image `shipstone/app-hazelcast:1.0`

